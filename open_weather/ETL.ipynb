{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from graph_gen import pollution_epa\n",
    "from config import pyowm_api_key\n",
    "\n",
    "import pandas as pd\n",
    "import pyowm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection to SQL\n",
    "engine = create_engine(\"mysql://root:password@localhost/weather_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in initial, consolidated dataset\n",
    "# df = pd.read_csv('california_cities.csv').set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into SQL.\n",
    "# df.to_sql(name='california_weather',con=engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to make sure the data is there.\n",
    "query = '''\n",
    "select * from california_weather\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>type</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>uv_index</th>\n",
       "      <th>aqi</th>\n",
       "      <th>category</th>\n",
       "      <th>dominant_pollutant</th>\n",
       "      <th>date</th>\n",
       "      <th>temperature</th>\n",
       "      <th>cloud</th>\n",
       "      <th>pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelanto</td>\n",
       "      <td>City</td>\n",
       "      <td>San Bernardino</td>\n",
       "      <td>california</td>\n",
       "      <td>34.582770</td>\n",
       "      <td>-117.409215</td>\n",
       "      <td>2.98</td>\n",
       "      <td>41</td>\n",
       "      <td>Good air quality</td>\n",
       "      <td>o3</td>\n",
       "      <td>2018-12-01 06:06:27</td>\n",
       "      <td>13.95</td>\n",
       "      <td>75</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agoura Hills</td>\n",
       "      <td>City</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>california</td>\n",
       "      <td>34.153340</td>\n",
       "      <td>-118.761676</td>\n",
       "      <td>3.00</td>\n",
       "      <td>48</td>\n",
       "      <td>Good air quality</td>\n",
       "      <td>pm25</td>\n",
       "      <td>2018-12-01 06:06:27</td>\n",
       "      <td>17.23</td>\n",
       "      <td>40</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>City</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>california</td>\n",
       "      <td>37.765206</td>\n",
       "      <td>-122.241636</td>\n",
       "      <td>2.00</td>\n",
       "      <td>61</td>\n",
       "      <td>Moderate air quality</td>\n",
       "      <td>pm25</td>\n",
       "      <td>2018-12-01 06:06:27</td>\n",
       "      <td>14.29</td>\n",
       "      <td>1</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albany</td>\n",
       "      <td>City</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>california</td>\n",
       "      <td>37.886870</td>\n",
       "      <td>-122.297747</td>\n",
       "      <td>1.97</td>\n",
       "      <td>61</td>\n",
       "      <td>Moderate air quality</td>\n",
       "      <td>pm25</td>\n",
       "      <td>2018-12-01 06:06:27</td>\n",
       "      <td>14.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alhambra</td>\n",
       "      <td>City</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>california</td>\n",
       "      <td>34.095287</td>\n",
       "      <td>-118.127015</td>\n",
       "      <td>3.00</td>\n",
       "      <td>66</td>\n",
       "      <td>Moderate air quality</td>\n",
       "      <td>pm25</td>\n",
       "      <td>2018-12-01 06:06:27</td>\n",
       "      <td>17.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               city  type          county       state        lat         lng  \\\n",
       "index                                                                          \n",
       "0          Adelanto  City  San Bernardino  california  34.582770 -117.409215   \n",
       "1      Agoura Hills  City     Los Angeles  california  34.153340 -118.761676   \n",
       "2           Alameda  City         Alameda  california  37.765206 -122.241636   \n",
       "3            Albany  City         Alameda  california  37.886870 -122.297747   \n",
       "4          Alhambra  City     Los Angeles  california  34.095287 -118.127015   \n",
       "\n",
       "       uv_index  aqi              category dominant_pollutant  \\\n",
       "index                                                           \n",
       "0          2.98   41      Good air quality                 o3   \n",
       "1          3.00   48      Good air quality               pm25   \n",
       "2          2.00   61  Moderate air quality               pm25   \n",
       "3          1.97   61  Moderate air quality               pm25   \n",
       "4          3.00   66  Moderate air quality               pm25   \n",
       "\n",
       "                     date  temperature  cloud  pressure  wind_speed  rain  \n",
       "index                                                                      \n",
       "0     2018-12-01 06:06:27        13.95     75    1015.0         5.1  0.00  \n",
       "1     2018-12-01 06:06:27        17.23     40    1016.0         3.6  0.00  \n",
       "2     2018-12-01 06:06:27        14.29      1    1020.0         2.1  1.02  \n",
       "3     2018-12-01 06:06:27        14.60      1    1020.0         2.1  1.02  \n",
       "4     2018-12-01 06:06:27        17.37      1    1015.0         2.1  0.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read query and set the index to the csv's index. Clean up column names so all are uniform.\n",
    "df = pd.read_sql_query(query, engine).set_index('index')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidating scraping functions to update weather values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from all group members was fused into this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_data(df):\n",
    "    \n",
    "    '''Takes in dataframe with city coordinates and returns of updated weather data for each city\n",
    "        via OpenWeatherMap and Breezometer APIs.'''\n",
    "\n",
    "    temperature = []\n",
    "    clouds = []\n",
    "    pressure = []\n",
    "    rain = []\n",
    "    date = []\n",
    "    wind = []\n",
    "    uv_index = []\n",
    "    \n",
    "    aqi = []\n",
    "    category = []\n",
    "    dominant_pollutant = []\n",
    "    \n",
    "    # Initialize connection to pyowm\n",
    "    owm = pyowm.OWM(pyowm_api_key) \n",
    "\n",
    "    for city,lat,lng in zip(df['city'],df['lat'],df['lng']):\n",
    "        print(f\"Gathering data for {city}...\")\n",
    "        \n",
    "        ## Make API calls to OpenWeatherMap: ##\n",
    "        try:\n",
    "            # Get weather and uv index data at coordinates specified.\n",
    "            weather = owm.weather_at_coords(lat, lng)\n",
    "            uvi = owm.uvindex_around_coords(lat, lng)\n",
    "        except:\n",
    "            print(f\"Error adding data for {city}. Appending NaN for all OpenWeatherMap categories.\")\n",
    "            temperature.append(\"NaN\")\n",
    "            clouds.append(\"NaN\")\n",
    "            pressure.append(\"NaN\")\n",
    "            date.append(\"NaN\")\n",
    "            wind.append(\"NaN\")\n",
    "            uv_index.append(\"NaN\")\n",
    "            rain.append(\"NaN\")\n",
    "        else:\n",
    "            weather_data = weather.get_weather()\n",
    "            \n",
    "            # Add data to lists\n",
    "            temperature.append(weather_data.get_temperature('fahrenheit')['temp'])\n",
    "            clouds.append(weather_data.get_clouds())\n",
    "            pressure.append(weather_data.get_pressure()['press'])\n",
    "            date.append(weather_data.get_reference_time(timeformat='iso'))\n",
    "            wind.append(weather_data.get_wind()['speed'])\n",
    "            uv_index.append(uvi.get_value())\n",
    "\n",
    "            precip = weather_data.get_rain()\n",
    "\n",
    "            # Account for empty rain data.\n",
    "            if precip == {}:\n",
    "                rain.append(0)\n",
    "            else:\n",
    "                rain.extend([v for v in precip.values()])\n",
    "        \n",
    "        ## Make API calls to Breezometer for air quality data:\n",
    "        data = pollution_epa(lat,lng)\n",
    "        \n",
    "        if data:\n",
    "            index = data['data']['indexes']['usa_epa']\n",
    "\n",
    "            air_quality = index['aqi']\n",
    "            categories = index['category']\n",
    "            dom_pollutant = index['dominant_pollutant']\n",
    "\n",
    "            aqi.append(air_quality)\n",
    "            category.append(categories)\n",
    "            dominant_pollutant.append(dom_pollutant)\n",
    "            \n",
    "        else:\n",
    "            aqi.append(\"NaN\")\n",
    "            category.append(\"NaN\")\n",
    "            dominant_pollutant.append(\"NaN\")\n",
    "        \n",
    "        # sleep for 1.1 second. Limited to 60 API calls/min\n",
    "        time.sleep(1.1)    \n",
    "        \n",
    "    return temperature,clouds,pressure,rain,date,wind,uv_index,aqi,category,dominant_pollutant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_df(df):\n",
    "    \n",
    "    '''Updates dataframe columns with new weather data.'''\n",
    "    \n",
    "    temperature,clouds,pressure,rain,date,wind,uv_index,aqi,category,dominant_pollutant = get_weather_data(df)\n",
    "    \n",
    "    df['temperature'] = temperature\n",
    "    df['cloud'] = clouds\n",
    "    df['pressure'] = pressure\n",
    "    df['rain'] = rain\n",
    "    df['date'] = pd.to_datetime(date)\n",
    "    df['wind_speed'] = wind\n",
    "    df['uv_index'] = uv_index\n",
    "    df['aqi'] = aqi\n",
    "    df['category'] = category\n",
    "    df['dominant_pollutant'] = dominant_pollutant\n",
    "    \n",
    "#     df.to_sql(name='california_weather',con=engine,if_exists='replace')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering data for Adelanto...\n",
      "Gathering data for Agoura Hills...\n",
      "Gathering data for Alameda...\n",
      "Gathering data for Albany...\n",
      "Gathering data for Alhambra...\n",
      "Gathering data for Aliso Viejo...\n",
      "Gathering data for Alturas...\n",
      "Gathering data for Amador City...\n",
      "Gathering data for American Canyon...\n",
      "Gathering data for Anaheim...\n",
      "Gathering data for Anderson...\n",
      "Gathering data for Angels Camp...\n",
      "Gathering data for Antioch...\n",
      "Gathering data for Apple Valley...\n",
      "Gathering data for Arcadia...\n",
      "Gathering data for Arcata...\n",
      "Gathering data for Arroyo Grande...\n",
      "Gathering data for Artesia...\n",
      "Gathering data for Arvin...\n",
      "Gathering data for Atascadero...\n",
      "Gathering data for Atherton...\n",
      "Gathering data for Atwater...\n",
      "Gathering data for Auburn...\n",
      "Gathering data for Avalon...\n",
      "Gathering data for Avenal...\n",
      "Gathering data for Azusa...\n",
      "Gathering data for Bakersfield...\n",
      "Gathering data for Baldwin Park...\n",
      "Gathering data for Banning...\n",
      "Gathering data for Barstow...\n",
      "Gathering data for Beaumont...\n",
      "Gathering data for Bell...\n",
      "Gathering data for Bell Gardens...\n",
      "Gathering data for Bellflower...\n",
      "Gathering data for Belmont...\n",
      "Gathering data for Belvedere...\n",
      "Gathering data for Benicia...\n",
      "Gathering data for Berkeley...\n",
      "Gathering data for Beverly Hills...\n",
      "Gathering data for Big Bear Lake...\n",
      "Gathering data for Biggs...\n",
      "Gathering data for Bishop...\n",
      "Gathering data for Blue Lake...\n",
      "Gathering data for Blythe...\n",
      "Gathering data for Bradbury...\n",
      "Gathering data for Brawley...\n",
      "Gathering data for Brea...\n",
      "Gathering data for Brentwood...\n",
      "Gathering data for Brisbane...\n",
      "Gathering data for Buellton...\n",
      "Gathering data for Buena Park...\n",
      "Gathering data for Burbank...\n",
      "Gathering data for Burlingame...\n",
      "Gathering data for Calabasas...\n",
      "Gathering data for Calexico...\n",
      "Gathering data for California City...\n",
      "Gathering data for Calimesa...\n",
      "Gathering data for Calipatria...\n",
      "Gathering data for Calistoga...\n",
      "Gathering data for Camarillo...\n",
      "Gathering data for Campbell...\n",
      "Gathering data for Canyon Lake...\n",
      "Gathering data for Capitola...\n",
      "Gathering data for Carlsbad...\n",
      "Gathering data for Carmel-by-the-Sea...\n",
      "Gathering data for Carpinteria...\n",
      "Gathering data for Carson...\n",
      "Gathering data for Cathedral City...\n",
      "Gathering data for Ceres...\n",
      "Gathering data for Cerritos...\n",
      "Gathering data for Chico...\n",
      "Gathering data for Chino...\n",
      "Gathering data for Chino Hills...\n",
      "Gathering data for Chowchilla...\n",
      "Gathering data for Chula Vista...\n",
      "Gathering data for Citrus Heights...\n",
      "Gathering data for Claremont...\n",
      "Gathering data for Clayton...\n",
      "Gathering data for Clearlake...\n",
      "Gathering data for Cloverdale...\n",
      "Gathering data for Clovis...\n",
      "Gathering data for Coachella...\n",
      "Gathering data for Coalinga...\n",
      "Gathering data for Colfax...\n",
      "Gathering data for Colma...\n",
      "Gathering data for Colton...\n",
      "Gathering data for Colusa...\n",
      "Gathering data for Commerce...\n",
      "Gathering data for Compton...\n",
      "Gathering data for Concord...\n",
      "Gathering data for Corcoran...\n",
      "Gathering data for Corning...\n",
      "Gathering data for Corona...\n",
      "Gathering data for Coronado...\n",
      "Gathering data for Corte Madera...\n",
      "Gathering data for Costa Mesa...\n",
      "Gathering data for Cotati...\n",
      "Gathering data for Covina...\n",
      "Gathering data for Crescent City...\n",
      "Gathering data for Cudahy...\n",
      "Gathering data for Culver City...\n",
      "Gathering data for Cupertino...\n",
      "Gathering data for Cypress...\n",
      "Gathering data for Daly City...\n",
      "Gathering data for Dana Point...\n",
      "Gathering data for Danville...\n",
      "Gathering data for Davis...\n",
      "Gathering data for Del Mar...\n",
      "Gathering data for Del Rey Oaks...\n",
      "Gathering data for Delano...\n",
      "Gathering data for Desert Hot Springs...\n",
      "Gathering data for Diamond Bar...\n",
      "Gathering data for Dinuba...\n",
      "Gathering data for Dixon...\n",
      "Gathering data for Dorris...\n",
      "Gathering data for Dos Palos...\n",
      "Gathering data for Downey...\n",
      "Gathering data for Duarte...\n",
      "Gathering data for Dublin...\n",
      "Gathering data for Dunsmuir...\n",
      "Gathering data for East Palo Alto...\n",
      "Gathering data for Eastvale...\n",
      "Gathering data for El Cajon...\n",
      "Gathering data for El Centro...\n",
      "Gathering data for El Cerrito...\n",
      "Gathering data for El Monte...\n",
      "Gathering data for El Segundo...\n",
      "Gathering data for Elk Grove...\n",
      "Gathering data for Emeryville...\n",
      "Gathering data for Encinitas...\n",
      "Gathering data for Escalon...\n",
      "Gathering data for Escondido...\n",
      "Gathering data for Etna...\n",
      "Gathering data for Eureka...\n",
      "Gathering data for Exeter...\n",
      "Gathering data for Fairfax...\n",
      "Gathering data for Fairfield...\n",
      "Gathering data for Farmersville...\n",
      "Gathering data for Ferndale...\n",
      "Gathering data for Fillmore...\n",
      "Gathering data for Firebaugh...\n",
      "Gathering data for Folsom...\n",
      "Gathering data for Fontana...\n",
      "Gathering data for Fort Bragg...\n",
      "Gathering data for Fort Jones...\n",
      "Gathering data for Fortuna...\n",
      "Gathering data for Foster City...\n",
      "Gathering data for Fountain Valley...\n",
      "Gathering data for Fowler...\n",
      "Gathering data for Fremont...\n",
      "Gathering data for Fresno...\n",
      "Gathering data for Fullerton...\n",
      "Gathering data for Galt...\n",
      "Gathering data for Garden Grove...\n",
      "Gathering data for Gardena...\n",
      "Gathering data for Gilroy...\n",
      "Gathering data for Glendale...\n",
      "Gathering data for Glendora...\n",
      "Gathering data for Goleta...\n",
      "Gathering data for Gonzales...\n",
      "Gathering data for Grand Terrace...\n",
      "Gathering data for Grass Valley...\n",
      "Gathering data for Greenfield...\n",
      "Gathering data for Gridley...\n",
      "Gathering data for Grover Beach...\n",
      "Gathering data for Guadalupe...\n",
      "Gathering data for Gustine...\n",
      "Gathering data for Half Moon Bay...\n",
      "Gathering data for Hanford...\n",
      "Gathering data for Hawaiian Gardens...\n",
      "Gathering data for Hawthorne...\n",
      "Gathering data for Hayward...\n",
      "Gathering data for Healdsburg...\n",
      "Gathering data for Hemet...\n",
      "Gathering data for Hercules...\n",
      "Gathering data for Hermosa Beach...\n",
      "Gathering data for Hesperia...\n",
      "Gathering data for Hidden Hills...\n",
      "Gathering data for Highland...\n",
      "Gathering data for Hillsborough...\n",
      "Gathering data for Hollister...\n",
      "Gathering data for Holtville...\n",
      "Gathering data for Hughson...\n",
      "Gathering data for Huntington Beach...\n",
      "Gathering data for Huntington Park...\n",
      "Gathering data for Huron...\n",
      "Gathering data for Imperial...\n",
      "Gathering data for Imperial Beach...\n",
      "Gathering data for Indian Wells...\n",
      "Gathering data for Indio...\n",
      "Gathering data for Industry...\n",
      "Gathering data for Inglewood...\n",
      "Gathering data for Ione...\n",
      "Gathering data for Irvine...\n",
      "Gathering data for Irwindale...\n",
      "Gathering data for Isleton...\n",
      "Gathering data for Jackson...\n",
      "Gathering data for Jurupa Valley...\n",
      "Gathering data for Kerman...\n",
      "Gathering data for King City...\n",
      "Gathering data for Kingsburg...\n",
      "Gathering data for La CaÃ±ada Flintridge...\n",
      "Gathering data for La Habra...\n",
      "Gathering data for La Habra Heights...\n",
      "Gathering data for La Mesa...\n",
      "Gathering data for La Mirada...\n",
      "Gathering data for La Palma...\n",
      "Gathering data for La Puente...\n",
      "Gathering data for La Quinta...\n",
      "Gathering data for La Verne...\n",
      "Gathering data for Lafayette...\n",
      "Gathering data for Laguna Beach...\n",
      "Gathering data for Laguna Hills...\n",
      "Gathering data for Laguna Niguel...\n",
      "Gathering data for Laguna Woods...\n",
      "Gathering data for Lake Elsinore...\n",
      "Gathering data for Lake Forest...\n",
      "Gathering data for Lakeport...\n",
      "Gathering data for Lakewood...\n",
      "Gathering data for Lancaster...\n",
      "Gathering data for Larkspur...\n",
      "Gathering data for Lathrop...\n",
      "Gathering data for Lawndale...\n",
      "Gathering data for Lemon Grove...\n",
      "Gathering data for Lemoore...\n",
      "Gathering data for Lincoln...\n",
      "Gathering data for Lindsay...\n",
      "Gathering data for Live Oak...\n",
      "Gathering data for Livermore...\n",
      "Gathering data for Livingston...\n",
      "Gathering data for Lodi...\n",
      "Gathering data for Loma Linda...\n",
      "Gathering data for Lomita...\n",
      "Gathering data for Lompoc...\n",
      "Gathering data for Long Beach...\n",
      "Gathering data for Loomis...\n",
      "Gathering data for Los Alamitos...\n",
      "Gathering data for Los Altos...\n",
      "Gathering data for Los Altos Hills...\n",
      "Gathering data for Los Angeles...\n",
      "Gathering data for Los Banos...\n",
      "Gathering data for Los Gatos...\n",
      "Gathering data for Loyalton...\n",
      "Gathering data for Lynwood...\n",
      "Gathering data for Madera...\n",
      "Gathering data for Malibu...\n",
      "Gathering data for Mammoth Lakes...\n",
      "Gathering data for Manhattan Beach...\n",
      "Gathering data for Manteca...\n",
      "Gathering data for Maricopa...\n",
      "Gathering data for Marina...\n",
      "Gathering data for Martinez...\n",
      "Gathering data for Marysville...\n",
      "Gathering data for Maywood...\n",
      "Gathering data for McFarland...\n",
      "Gathering data for Mendota...\n",
      "Gathering data for Menifee...\n",
      "Gathering data for Menlo Park...\n",
      "Gathering data for Merced...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering data for Mill Valley...\n",
      "Gathering data for Millbrae...\n",
      "Gathering data for Milpitas...\n",
      "Gathering data for Mission Viejo...\n",
      "Gathering data for Modesto...\n",
      "Gathering data for Monrovia...\n",
      "Gathering data for Montague...\n",
      "Gathering data for Montclair...\n",
      "Gathering data for Monte Sereno...\n",
      "Gathering data for Montebello...\n",
      "Gathering data for Monterey...\n",
      "Gathering data for Monterey Park...\n",
      "Gathering data for Moorpark...\n",
      "Gathering data for Moraga...\n",
      "Gathering data for Moreno Valley...\n",
      "Gathering data for Morgan Hill...\n",
      "Gathering data for Morro Bay...\n",
      "Gathering data for Mount Shasta...\n",
      "Gathering data for Mountain View...\n",
      "Gathering data for Murrieta...\n",
      "Gathering data for Napa...\n",
      "Gathering data for National City...\n",
      "Gathering data for Needles...\n",
      "Gathering data for Nevada City...\n",
      "Gathering data for Newark...\n",
      "Gathering data for Newman...\n",
      "Gathering data for Newport Beach...\n",
      "Gathering data for Norco...\n",
      "Gathering data for Norwalk...\n",
      "Gathering data for Novato...\n",
      "Gathering data for Oakdale...\n",
      "Gathering data for Oakland...\n",
      "Gathering data for Oakley...\n",
      "Gathering data for Oceanside...\n",
      "Gathering data for Ojai...\n",
      "Gathering data for Ontario...\n",
      "Gathering data for Orange...\n",
      "Gathering data for Orange Cove...\n",
      "Gathering data for Orinda...\n"
     ]
    }
   ],
   "source": [
    "recent_data = update_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql_query('''describe california_weather''',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def df_geodata(filename=None,query=None):    \n",
    "#     \"\"\"\n",
    "#     Returns dataframe with pollution data from city list dataframe. Makes API calls via 'pollution_epa'\n",
    "#     to scrape latest data.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     if filename and query:\n",
    "#         return \"You must pass either a csv filename or a SQL query. You cannot pass two arguments.\"\n",
    "#     elif filename == None and query == None:\n",
    "#         return \"Error: No arguments were passed to this function.\"\n",
    "#     elif filename:\n",
    "#         df = pd.read_csv(filename)\n",
    "#     else:\n",
    "#         df = pd.read_sql_query(query).set_index('index')\n",
    "    \n",
    "#     aqi = []\n",
    "#     category = []\n",
    "#     dominant_pollutant = []\n",
    "#     date = []\n",
    "\n",
    "\n",
    "#     for lat,lng in zip(df['lat'],df['lng']):\n",
    "#         # Get pollution data.\n",
    "#         data = pollution_epa(lat,lng)\n",
    "        \n",
    "#         if data != None:\n",
    "#             index = data['data']['indexes']['usa_epa']\n",
    "\n",
    "#             air_quality = index['aqi']\n",
    "#             categories = index['category']\n",
    "#             dom_pollutant = index['dominant_pollutant']\n",
    "#             datetime = data['data']['datetime']\n",
    "\n",
    "#             aqi.append(air_quality)\n",
    "#             category.append(categories)\n",
    "#             dominant_pollutant.append(dom_pollutant)\n",
    "#             date.append(datetime)\n",
    "            \n",
    "#         else:\n",
    "#             aqi.append(\"NaN\")\n",
    "#             category.append(\"NaN\")\n",
    "#             dominant_pollutant.append(\"NaN\")\n",
    "#             date.append(\"NaN\")          \n",
    "    \n",
    "#     # Update columns with latest data\n",
    "#     df['aqi'] = aqi\n",
    "#     df['category'] = category\n",
    "#     df['dominant_pollutant'] = dominant_pollutant\n",
    "#     df['datetime'] = date\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_map(df):\n",
    "#     '''\n",
    "#     Generates HTML for map from pollution data.\n",
    "#     '''\n",
    "#     data = [\n",
    "#     go.Scattermapbox(\n",
    "#         lat=round(df['lat'],3),\n",
    "#         lon=round(df['lng'],3),\n",
    "#         mode='markers',\n",
    "#         marker=dict(\n",
    "#             size=df['aqi']/10,\n",
    "#             color= df['aqi'],\n",
    "#             colorscale = 'Jet',\n",
    "#         ),\n",
    "#         text= marker_text(df)\n",
    "#         )\n",
    "#     ]\n",
    "\n",
    "#     layout = go.Layout(\n",
    "#         autosize=True,\n",
    "#         hovermode='closest',\n",
    "#         mapbox=dict(\n",
    "#             accesstoken=mapbox_api_key,\n",
    "#             bearing=0,\n",
    "#             center=dict(\n",
    "#                 lat=36,\n",
    "#                 lon=-119\n",
    "#             ),\n",
    "#             style='dark',\n",
    "#             pitch=0,\n",
    "#             zoom=4\n",
    "#         ),\n",
    "#     )\n",
    "\n",
    "#     fig = dict(data=data, layout=layout)\n",
    "\n",
    "#     map_html = plotly.offline.plot(fig, include_plotlyjs=False, output_type='div')\n",
    "    \n",
    "#     return map_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def df_geodata(filename=None,query=None):    \n",
    "#     \"\"\"\n",
    "#     Returns dataframe with pollution data from city list dataframe. Makes API calls via 'pollution_epa'\n",
    "#     to scrape latest data.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     if filename and query:\n",
    "#         return \"You must pass either a csv filename or a SQL query. You cannot pass two arguments.\"\n",
    "#     elif filename == None and query == None:\n",
    "#         return \"Error: No arguments were passed to this function.\"\n",
    "#     elif filename:\n",
    "#         df = pd.read_csv(filename)\n",
    "#     else:\n",
    "#         df = pd.read_sql_query(query).set_index('index')\n",
    "    \n",
    "#     aqi = []\n",
    "#     category = []\n",
    "#     dominant_pollutant = []\n",
    "#     date = []\n",
    "\n",
    "\n",
    "#     for lat,lng in zip(df['lat'],df['lng']):\n",
    "#         # Get pollution data.\n",
    "#         data = pollution_epa(lat,lng)\n",
    "        \n",
    "#         if data != None:\n",
    "#             index = data['data']['indexes']['usa_epa']\n",
    "\n",
    "#             air_quality = index['aqi']\n",
    "#             categories = index['category']\n",
    "#             dom_pollutant = index['dominant_pollutant']\n",
    "#             datetime = data['data']['datetime']\n",
    "\n",
    "#             aqi.append(air_quality)\n",
    "#             category.append(categories)\n",
    "#             dominant_pollutant.append(dom_pollutant)\n",
    "#             date.append(datetime)\n",
    "            \n",
    "#         else:\n",
    "#             aqi.append(\"NaN\")\n",
    "#             category.append(\"NaN\")\n",
    "#             dominant_pollutant.append(\"NaN\")\n",
    "#             date.append(\"NaN\")          \n",
    "    \n",
    "#     # Update columns with latest data\n",
    "#     df['aqi'] = aqi\n",
    "#     df['category'] = category\n",
    "#     df['dominant_pollutant'] = dominant_pollutant\n",
    "#     df['datetime'] = date\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_map(df2)\n",
    "# df = df_geodata('california_cities.csv')\n",
    "# df.to_sql(name='california_pollution',con=engine,if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
